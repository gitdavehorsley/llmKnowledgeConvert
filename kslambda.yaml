AWSTemplateFormatVersion: '2010-09-09'
Description: 'Document Conversion Lambda Stack - Lambda Function, Layer, and S3 Notifications (Stack 2 of 2)'

Parameters:
  ProjectName:
    Type: String
    Default: knowledge-converter
    Description: Project name (must match infrastructure stack)
    
  Environment:
    Type: String
    Default: poc
    AllowedValues: 
      - poc
      - dev
      - staging
      - prod
    Description: Environment name (must match infrastructure stack)
    
  # ================================
  # Lambda Configuration
  # ================================
  LambdaMemorySize:
    Type: Number
    Default: 1536
    MinValue: 512
    MaxValue: 10240
    Description: Lambda memory size in MB (affects CPU allocation)
    
  LambdaTimeout:
    Type: Number
    Default: 600
    MinValue: 60
    MaxValue: 900
    Description: Lambda timeout in seconds (max 15 minutes)
    
  LambdaArchitecture:
    Type: String
    Default: x86_64
    AllowedValues: [x86_64, arm64]
    Description: Lambda processor architecture
    
  # ================================
  # Layer Configuration
  # ================================
  LayerDeploymentMethod:
    Type: String
    Default: inline
    AllowedValues: [inline, s3]
    Description: How to deploy the layer (inline for testing, s3 for production)
    
  LayerS3Bucket:
    Type: String
    Default: ""
    Description: S3 bucket containing layer zip file (only needed if LayerDeploymentMethod=s3)
    
  LayerS3Key:
    Type: String
    Default: "layers/document-processing-layer.zip"
    Description: S3 key for layer zip file (only needed if LayerDeploymentMethod=s3)
    
  # ================================
  # Processing Configuration
  # ================================
  MaxFileSizeMB:
    Type: Number
    Default: 50
    MinValue: 1
    MaxValue: 500
    Description: Maximum file size to process in MB
    
  EnableImageProcessing:
    Type: String
    Default: "false"
    AllowedValues: ["true", "false"]
    Description: Enable image processing in PDFs (increases memory usage)
    
  # ================================
  # Deployment Configuration
  # ================================
  DeploymentPackageMethod:
    Type: String
    Default: inline
    AllowedValues: [inline, s3]
    Description: How to deploy Lambda code (inline for development, s3 for production)
    
  CodeS3Bucket:
    Type: String
    Default: ""
    Description: S3 bucket containing Lambda code zip (only needed if DeploymentPackageMethod=s3)
    
  CodeS3Key:
    Type: String
    Default: "lambda/document-converter.zip"
    Description: S3 key for Lambda code zip (only needed if DeploymentPackageMethod=s3)
    
  # ================================
  # Notifications Configuration
  # ================================
  EnableNotifications:
    Type: String
    Default: "false"
    AllowedValues: ["true", "false"]
    Description: Whether to enable SNS notifications and wire alarms to the imported topic

Conditions:
  UseInlineLayer: !Equals [!Ref LayerDeploymentMethod, "inline"]
  UseS3Layer: !Equals [!Ref LayerDeploymentMethod, "s3"]
  UseInlineCode: !Equals [!Ref DeploymentPackageMethod, "inline"]
  UseS3Code: !Equals [!Ref DeploymentPackageMethod, "s3"]
  HasNotificationTopic: !Equals [!Ref EnableNotifications, "true"]

Resources:

  # ================================
  # Lambda Layer (Inline for Development)
  # ================================
  DocumentProcessingLayerInline:
    Type: AWS::Lambda::LayerVersion
    Condition: UseInlineLayer
    Properties:
      LayerName: !Sub "${ProjectName}-document-processing-inline"
      Description: "Document processing libraries: pdfplumber, python-docx, pandas (inline deployment)"
      Content:
        ZipFile: |
          # This is a placeholder for inline deployment
          # In production, you should use S3 deployment with pre-built layer
          import sys
          print("Layer placeholder - use S3 deployment for production")
      CompatibleRuntimes:
        - python3.11
      CompatibleArchitectures:
        - !Ref LambdaArchitecture

  # ================================
  # Lambda Layer (S3 for Production)
  # ================================
  DocumentProcessingLayerS3:
    Type: AWS::Lambda::LayerVersion
    Condition: UseS3Layer
    Properties:
      LayerName: !Sub "${ProjectName}-document-processing"
      Description: "Document processing libraries: pdfplumber, python-docx, pandas"
      Content:
        S3Bucket: !Ref LayerS3Bucket
        S3Key: !Ref LayerS3Key
      CompatibleRuntimes:
        - python3.11
      CompatibleArchitectures:
        - !Ref LambdaArchitecture

  # ================================
  # Lambda Function
  # ================================
  DocumentConverterFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${ProjectName}-document-converter"
      Runtime: python3.11
      Handler: index.lambda_handler
      Role: 
        Fn::ImportValue:
          Fn::Sub: "${ProjectName}-task-role-arn"
      MemorySize: !Ref LambdaMemorySize
      Timeout: !Ref LambdaTimeout
      Architectures:
        - !Ref LambdaArchitecture
      EphemeralStorage:
        Size: 2048  # 2GB for document processing
      Environment:
        Variables:
          # Import values from infrastructure stack
          MARKDOWN_BUCKET_NAME: 
            Fn::ImportValue:
              Fn::Sub: "${ProjectName}-markdown-bucket-name"
          LOG_LEVEL: INFO
          ENABLE_DETAILED_MONITORING: "false"
          SNS_TOPIC_ARN: !If 
            - HasNotificationTopic
            - Fn::ImportValue:
                Fn::Sub: "${ProjectName}-failure-topic-arn"
            - ""
          PROJECT_NAME: !Ref ProjectName
          ENVIRONMENT: !Ref Environment
          MAX_FILE_SIZE_MB: !Ref MaxFileSizeMB
          ENABLE_IMAGE_PROCESSING: !Ref EnableImageProcessing
          AWS_ACCOUNT_ID: !Ref AWS::AccountId
          AWS_DEPLOYMENT_REGION: !Ref AWS::Region
      Layers:
        - !If 
          - UseInlineLayer
          - !Ref DocumentProcessingLayerInline
          - !Ref DocumentProcessingLayerS3
      Code: !If
        - UseInlineCode
        - ZipFile: |
            import os, json, boto3
            from urllib.parse import unquote_plus

            s3 = boto3.client('s3')
            MARKDOWN_BUCKET = os.environ.get('MARKDOWN_BUCKET_NAME', '')

            def lambda_handler(event, context):
                """
                Process SQS messages containing S3 events
                Each SQS message contains an S3 event in its body
                """
                results = []

                # Process each SQS message
                for sqs_record in event.get('Records', []):
                    try:
                        # Parse the S3 event from the SQS message body
                        s3_event = json.loads(sqs_record['body'])

                        # Process each S3 record in the event
                        for s3_record in s3_event.get('Records', []):
                            try:
                                b = s3_record['s3']['bucket']['name']
                                k = unquote_plus(s3_record['s3']['object']['key'])

                                # Skip if this is a folder or non-document file
                                if k.endswith('/') or not any(k.lower().endswith(ext) for ext in ['.pdf', '.docx', '.doc']):
                                    continue

                                md_key = k.rsplit('.', 1)[0] + '.md'
                                body = f"# Placeholder Conversion\n\nSource: s3://{b}/{k}\n"

                                s3.put_object(
                                    Bucket=MARKDOWN_BUCKET,
                                    Key=md_key,
                                    Body=body.encode('utf-8'),
                                    ContentType='text/markdown'
                                )

                                results.append({
                                    'source': f's3://{b}/{k}',
                                    'output': f's3://{MARKDOWN_BUCKET}/{md_key}',
                                    'message_id': sqs_record.get('messageId')
                                })

                            except Exception as e:
                                results.append({
                                    'source': s3_record.get('s3', {}),
                                    'error': str(e),
                                    'message_id': sqs_record.get('messageId')
                                })

                    except json.JSONDecodeError as e:
                        results.append({
                            'error': f'Failed to parse SQS message: {str(e)}',
                            'message_id': sqs_record.get('messageId')
                        })
                    except Exception as e:
                        results.append({
                            'error': f'Failed to process SQS message: {str(e)}',
                            'message_id': sqs_record.get('messageId')
                        })

                return {
                    'statusCode': 200,
                    'body': json.dumps({
                        'results': results,
                        'processed_messages': len(event.get('Records', []))
                    })
                }

        - S3Bucket: !Ref CodeS3Bucket
          S3Key: !Ref CodeS3Key
      DeadLetterConfig:
        TargetArn: !GetAtt FailureQueue.Arn
      Tags:
        - Key: Name
          Value: !Sub "${ProjectName}-document-converter"
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Stack
          Value: lambda

  # ================================
  # SQS Event Source Mapping for Lambda
  # ================================
  DocumentConverterSQSEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      FunctionName: !Ref DocumentConverterFunction
      EventSourceArn:
        Fn::ImportValue:
          Fn::Sub: "${ProjectName}-conversion-queue-arn"
      BatchSize: 10  # Process up to 10 messages per batch
      MaximumBatchingWindowInSeconds: 5  # Wait up to 5 seconds to accumulate messages
      Enabled: true
      # Note: MaximumConcurrency and ScalingConfig can be added for fine-tuning



  # ================================
  # S3 Bucket Notifications (connects to existing bucket)
  # ================================
  SourceBucketNotificationConfiguration:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        Fn::ImportValue:
          Fn::Sub: "${ProjectName}-source-bucket-name"
      NotificationConfiguration:
        QueueConfigurations:
          - Event: s3:ObjectCreated:*
            Queue:
              Fn::ImportValue:
                Fn::Sub: "${ProjectName}-conversion-queue-arn"
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .pdf
          - Event: s3:ObjectCreated:*
            Queue:
              Fn::ImportValue:
                Fn::Sub: "${ProjectName}-conversion-queue-arn"
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .docx
          - Event: s3:ObjectCreated:*
            Queue:
              Fn::ImportValue:
                Fn::Sub: "${ProjectName}-conversion-queue-arn"
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .doc

  # ================================
  # Dead Letter Queue for Failed Invocations
  # ================================
  FailureQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub "${ProjectName}-conversion-failures"
      MessageRetentionPeriod: 1209600  # 14 days
      VisibilityTimeoutSeconds: 60
      KmsMasterKeyId: alias/aws/sqs
      Tags:
        - Key: Name
          Value: !Sub "${ProjectName}-failure-queue"
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # ================================
  # CloudWatch Alarms for Monitoring
  # ================================
  LambdaErrorAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${ProjectName}-lambda-errors"
      AlarmDescription: "Lambda function errors"
      MetricName: Errors
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DocumentConverterFunction
      AlarmActions: !If
        - HasNotificationTopic
        - - Fn::ImportValue:
              Fn::Sub: "${ProjectName}-failure-topic-arn"
        - !Ref AWS::NoValue

  LambdaDurationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${ProjectName}-lambda-duration"
      AlarmDescription: "Lambda function duration approaching timeout"
      MetricName: Duration
      Namespace: AWS/Lambda
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Sub "${LambdaTimeout}000"  # Convert to milliseconds
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DocumentConverterFunction
      TreatMissingData: notBreaching

  LambdaThrottleAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${ProjectName}-lambda-throttles"
      AlarmDescription: "Lambda function throttles"
      MetricName: Throttles
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref DocumentConverterFunction

  # ================================
  # SQS Monitoring Alarms
  # ================================
  SQSQueueDepthAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${ProjectName}-sqs-queue-depth"
      AlarmDescription: "SQS queue has messages pending processing"
      MetricName: ApproximateNumberOfMessagesVisible
      Namespace: AWS/SQS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 100  # Alert if more than 100 messages pending
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: QueueName
          Value: !Sub "${ProjectName}-document-conversion-events"
      TreatMissingData: notBreaching

  SQSDLQMessagesAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${ProjectName}-sqs-dlq-messages"
      AlarmDescription: "Messages in dead letter queue indicate processing failures"
      MetricName: ApproximateNumberOfMessagesVisible
      Namespace: AWS/SQS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 1
      Threshold: 1  # Alert if any messages in DLQ
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: QueueName
          Value: !Sub "${ProjectName}-document-conversion-dlq"
      AlarmActions: !If
        - HasNotificationTopic
        - - Fn::ImportValue:
              Fn::Sub: "${ProjectName}-failure-topic-arn"
        - !Ref AWS::NoValue

  # ================================
  # Lambda Function URL (Optional - for testing)
  # ================================
  DocumentConverterFunctionUrl:
    Type: AWS::Lambda::Url
    Properties:
      TargetFunctionArn: !Ref DocumentConverterFunction
      AuthType: NONE
      Cors:
        AllowCredentials: false
        AllowMethods:
          - POST
        AllowOrigins:
          - "*"
        AllowHeaders:
          - content-type
        MaxAge: 86400

# ================================
# Outputs
# ================================
Outputs:
  # Lambda Function Information
  LambdaFunctionName:
    Description: Name of the document converter Lambda function
    Value: !Ref DocumentConverterFunction
    Export:
      Name: !Sub "${ProjectName}-lambda-function-name"

  LambdaFunctionArn:
    Description: ARN of the document converter Lambda function
    Value: !GetAtt DocumentConverterFunction.Arn
    Export:
      Name: !Sub "${ProjectName}-lambda-function-arn"

  # Layer Information
  LayerArn:
    Description: ARN of the document processing layer
    Value: !If
      - UseInlineLayer
      - !Ref DocumentProcessingLayerInline
      - !Ref DocumentProcessingLayerS3
    Export:
      Name: !Sub "${ProjectName}-layer-arn"

  LayerVersion:
    Description: Version of the document processing layer
    Value: !If
      - UseInlineLayer
      - !GetAtt DocumentProcessingLayerInline.Version
      - !GetAtt DocumentProcessingLayerS3.Version
    Export:
      Name: !Sub "${ProjectName}-layer-version"

  # Queue Information
  FailureQueueUrl:
    Description: URL of the failure queue for dead letter messages
    Value: !GetAtt FailureQueue.QueueUrl
    Export:
      Name: !Sub "${ProjectName}-failure-queue-url"

  FailureQueueArn:
    Description: ARN of the failure queue
    Value: !GetAtt FailureQueue.Arn
    Export:
      Name: !Sub "${ProjectName}-failure-queue-arn"

  # Function URL (for testing)
  FunctionUrl:
    Description: Lambda Function URL for direct testing
    Value: !GetAtt DocumentConverterFunctionUrl.FunctionUrl
    Export:
      Name: !Sub "${ProjectName}-function-url"

  # Configuration Summary
  LambdaConfiguration:
    Description: Summary of Lambda configuration
    Value: !Sub "${LambdaMemorySize}MB memory, ${LambdaTimeout}s timeout, ${LambdaArchitecture} architecture"
    Export:
      Name: !Sub "${ProjectName}-lambda-config"

  ProcessingConfiguration:
    Description: Document processing configuration
    Value: !Sub "Max file size: ${MaxFileSizeMB}MB, Image processing: ${EnableImageProcessing}"
    Export:
      Name: !Sub "${ProjectName}-processing-config"

  # Monitoring Endpoints
  CloudWatchLogGroup:
    Description: CloudWatch log group for Lambda function
    Value:
      Fn::ImportValue:
        Fn::Sub: "${ProjectName}-log-group-name"
    Export:
      Name: !Sub "${ProjectName}-lambda-log-group"

  # SQS Event Source Information
  SQSEventSourceMappingUUID:
    Description: UUID of the SQS event source mapping
    Value: !Ref DocumentConverterSQSEventSourceMapping
    Export:
      Name: !Sub "${ProjectName}-sqs-event-source-mapping"

  # Cross-Stack References Used
  ReferencedInfrastructureStack:
    Description: Infrastructure stack components referenced
    Value: !Sub "${ProjectName}-infrastructure"
    Export:
      Name: !Sub "${ProjectName}-infrastructure-reference"